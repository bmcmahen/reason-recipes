{"dependencies":[{"name":"../core/snapshot_version","loc":{"line":18,"column":33}},{"name":"../core/target_id_generator","loc":{"line":19,"column":36}},{"name":"../core/timestamp","loc":{"line":20,"column":26}},{"name":"../model/collections","loc":{"line":21,"column":28}},{"name":"../model/mutation_batch","loc":{"line":22,"column":31}},{"name":"../remote/remote_event","loc":{"line":23,"column":29}},{"name":"../util/assert","loc":{"line":24,"column":23}},{"name":"../util/log","loc":{"line":25,"column":18}},{"name":"../util/obj","loc":{"line":26,"column":23}},{"name":"./local_documents_view","loc":{"line":27,"column":37}},{"name":"./persistence_promise","loc":{"line":28,"column":36}},{"name":"./query_data","loc":{"line":29,"column":27}},{"name":"./reference_set","loc":{"line":30,"column":30}},{"name":"./remote_document_change_buffer","loc":{"line":31,"column":46}}],"generated":{"js":"\"use strict\";\n/**\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar snapshot_version_1 = require(\"../core/snapshot_version\");\nvar target_id_generator_1 = require(\"../core/target_id_generator\");\nvar timestamp_1 = require(\"../core/timestamp\");\nvar collections_1 = require(\"../model/collections\");\nvar mutation_batch_1 = require(\"../model/mutation_batch\");\nvar remote_event_1 = require(\"../remote/remote_event\");\nvar assert_1 = require(\"../util/assert\");\nvar log = require(\"../util/log\");\nvar objUtils = require(\"../util/obj\");\nvar local_documents_view_1 = require(\"./local_documents_view\");\nvar persistence_promise_1 = require(\"./persistence_promise\");\nvar query_data_1 = require(\"./query_data\");\nvar reference_set_1 = require(\"./reference_set\");\nvar remote_document_change_buffer_1 = require(\"./remote_document_change_buffer\");\nvar LOG_TAG = 'LocalStore';\n/**\n * Local storage in the Firestore client. Coordinates persistence components\n * like the mutation queue and remote document cache to present a\n * latency-compensated view of stored data.\n *\n * The LocalStore is responsible for accepting mutations from the Sync Engine.\n * Writes from the client are put into a queue as provisional Mutations until\n * they are processed by the RemoteStore and confirmed as having been written\n * to the server.\n *\n * The local store provides the local version of documents that have been\n * modified locally. It maintains the constraint:\n *\n *   LocalDocument = RemoteDocument + Active(LocalMutations)\n *\n * (Active mutations are those that are enqueued and have not been previously\n * acknowledged or rejected).\n *\n * The RemoteDocument (\"ground truth\") state is provided via the\n * applyChangeBatch method. It will be some version of a server-provided\n * document OR will be a server-provided document PLUS acknowledged mutations:\n *\n *   RemoteDocument' = RemoteDocument + Acknowledged(LocalMutations)\n *\n * Note that this \"dirty\" version of a RemoteDocument will not be identical to a\n * server base version, since it has LocalMutations added to it pending getting\n * an authoritative copy from the server.\n *\n * Since LocalMutations can be rejected by the server, we have to be able to\n * revert a LocalMutation that has already been applied to the LocalDocument\n * (typically done by replaying all remaining LocalMutations to the\n * RemoteDocument to re-apply).\n *\n * The LocalStore is responsible for the garbage collection of the documents it\n * contains. For now, it every doc referenced by a view, the mutation queue, or\n * the RemoteStore.\n *\n * It also maintains the persistence of mapping queries to resume tokens and\n * target ids. It needs to know this data about queries to properly know what\n * docs it would be allowed to garbage collect.\n *\n * The LocalStore must be able to efficiently execute queries against its local\n * cache of the documents, to provide the initial set of results before any\n * remote changes have been received.\n *\n * Note: In TypeScript, most methods return Promises since the implementation\n * may rely on fetching data from IndexedDB which is async.\n * These Promises will only be rejected on an I/O error or other internal\n * (unexpected) failure (e.g. failed assert) and always represent an\n * unrecoverable error (should be caught / reported by the async_queue).\n */\nvar LocalStore = /** @class */ (function () {\n    function LocalStore(\n        /** Manages our in-memory or durable persistence. */\n        persistence, initialUser, \n        /**\n         * The garbage collector collects documents that should no longer be\n         * cached (e.g. if they are no longer retained by the above reference sets\n         * and the garbage collector is performing eager collection).\n         */\n        garbageCollector) {\n        this.persistence = persistence;\n        this.garbageCollector = garbageCollector;\n        /**\n         * The set of document references maintained by any local views.\n         */\n        this.localViewReferences = new reference_set_1.ReferenceSet();\n        /** Maps a targetID to data about its query. */\n        this.targetIds = {};\n        /** Used to generate targetIDs for queries tracked locally. */\n        this.targetIdGenerator = target_id_generator_1.TargetIdGenerator.forLocalStore();\n        /**\n         * A heldBatchResult is a mutation batch result (from a write acknowledgement)\n         * that arrived before the watch stream got notified of a snapshot that\n         * includes the write.â€‚So we \"hold\" it until the watch stream catches up. It\n         * ensures that the local write remains visible (latency compensation) and\n         * doesn't temporarily appear reverted because the watch stream is slower than\n         * the write stream and so wasn't reflecting it.\n         *\n         * NOTE: Eventually we want to move this functionality into the remote store.\n         */\n        this.heldBatchResults = [];\n        this.mutationQueue = persistence.getMutationQueue(initialUser);\n        this.remoteDocuments = persistence.getRemoteDocumentCache();\n        this.queryCache = persistence.getQueryCache();\n        this.localDocuments = new local_documents_view_1.LocalDocumentsView(this.remoteDocuments, this.mutationQueue);\n        this.garbageCollector.addGarbageSource(this.localViewReferences);\n        this.garbageCollector.addGarbageSource(this.queryCache);\n        this.garbageCollector.addGarbageSource(this.mutationQueue);\n    }\n    /** Performs any initial startup actions required by the local store. */\n    LocalStore.prototype.start = function () {\n        var _this = this;\n        return this.persistence.runTransaction('Start LocalStore', function (txn) {\n            return _this.startMutationQueue(txn).next(function () { return _this.startQueryCache(txn); });\n        });\n    };\n    /**\n     * Tells the LocalStore that the currently authenticated user has changed.\n     *\n     * In response the local store switches the mutation queue to the new user and\n     * returns any resulting document changes.\n     */\n    LocalStore.prototype.handleUserChange = function (user) {\n        var _this = this;\n        return this.persistence.runTransaction('Handle user change', function (txn) {\n            // Swap out the mutation queue, grabbing the pending mutation batches\n            // before and after.\n            var oldBatches;\n            return _this.mutationQueue\n                .getAllMutationBatches(txn)\n                .next(function (promisedOldBatches) {\n                oldBatches = promisedOldBatches;\n                _this.garbageCollector.removeGarbageSource(_this.mutationQueue);\n                _this.mutationQueue = _this.persistence.getMutationQueue(user);\n                _this.garbageCollector.addGarbageSource(_this.mutationQueue);\n                return _this.startMutationQueue(txn);\n            })\n                .next(function () {\n                // Recreate our LocalDocumentsView using the new\n                // MutationQueue.\n                _this.localDocuments = new local_documents_view_1.LocalDocumentsView(_this.remoteDocuments, _this.mutationQueue);\n                return _this.mutationQueue.getAllMutationBatches(txn);\n            })\n                .next(function (newBatches) {\n                // Union the old/new changed keys.\n                var changedKeys = collections_1.documentKeySet();\n                for (var _i = 0, _a = [oldBatches, newBatches]; _i < _a.length; _i++) {\n                    var batches = _a[_i];\n                    for (var _b = 0, batches_1 = batches; _b < batches_1.length; _b++) {\n                        var batch = batches_1[_b];\n                        for (var _c = 0, _d = batch.mutations; _c < _d.length; _c++) {\n                            var mutation = _d[_c];\n                            changedKeys = changedKeys.add(mutation.key);\n                        }\n                    }\n                }\n                // Return the set of all (potentially) changed documents as the\n                // result of the user change.\n                return _this.localDocuments.getDocuments(txn, changedKeys);\n            });\n        });\n    };\n    LocalStore.prototype.startQueryCache = function (txn) {\n        var _this = this;\n        return this.queryCache.start(txn).next(function () {\n            var targetId = _this.queryCache.getHighestTargetId();\n            _this.targetIdGenerator = target_id_generator_1.TargetIdGenerator.forLocalStore(targetId);\n        });\n    };\n    LocalStore.prototype.startMutationQueue = function (txn) {\n        var _this = this;\n        return this.mutationQueue\n            .start(txn)\n            .next(function () {\n            // If we have any leftover mutation batch results from a prior run,\n            // just drop them.\n            // TODO(http://b/33446471): We probably need to repopulate\n            // heldBatchResults or similar instead, but that is not\n            // straightforward since we're not persisting the write ack versions.\n            _this.heldBatchResults = [];\n            return _this.mutationQueue.getHighestAcknowledgedBatchId(txn);\n        })\n            .next(function (highestAck) {\n            // TODO(mikelehen): This is the only usage of\n            // getAllMutationBatchesThroughBatchId(). Consider removing it in\n            // favor of a getAcknowledgedBatches() method.\n            if (highestAck !== mutation_batch_1.BATCHID_UNKNOWN) {\n                return _this.mutationQueue.getAllMutationBatchesThroughBatchId(txn, highestAck);\n            }\n            else {\n                return persistence_promise_1.PersistencePromise.resolve([]);\n            }\n        })\n            .next(function (ackedBatches) {\n            if (ackedBatches.length > 0) {\n                return _this.mutationQueue.removeMutationBatches(txn, ackedBatches);\n            }\n            else {\n                return persistence_promise_1.PersistencePromise.resolve();\n            }\n        });\n    };\n    /* Accept locally generated Mutations and commit them to storage. */\n    LocalStore.prototype.localWrite = function (mutations) {\n        var _this = this;\n        return this.persistence.runTransaction('Locally write mutations', function (txn) {\n            var batch;\n            var localWriteTime = timestamp_1.Timestamp.now();\n            return _this.mutationQueue\n                .addMutationBatch(txn, localWriteTime, mutations)\n                .next(function (promisedBatch) {\n                batch = promisedBatch;\n                // TODO(koss): This is doing an N^2 update by replaying ALL the\n                // mutations on each document (instead of just the ones added) in\n                // this batch.\n                var keys = batch.keys();\n                return _this.localDocuments.getDocuments(txn, keys);\n            })\n                .next(function (changedDocuments) {\n                return { batchId: batch.batchId, changes: changedDocuments };\n            });\n        });\n    };\n    /**\n     * Acknowledge the given batch.\n     *\n     * On the happy path when a batch is acknowledged, the local store will\n     *\n     *  + remove the batch from the mutation queue;\n     *  + apply the changes to the remote document cache;\n     *  + recalculate the latency compensated view implied by those changes (there\n     *    may be mutations in the queue that affect the documents but haven't been\n     *    acknowledged yet); and\n     *  + give the changed documents back the sync engine\n     *\n     * @returns The resulting (modified) documents.\n     */\n    LocalStore.prototype.acknowledgeBatch = function (batchResult) {\n        var _this = this;\n        return this.persistence.runTransaction('Acknowledge batch', function (txn) {\n            var affected;\n            return _this.mutationQueue\n                .acknowledgeBatch(txn, batchResult.batch, batchResult.streamToken)\n                .next(function () {\n                if (_this.shouldHoldBatchResult(batchResult.commitVersion)) {\n                    _this.heldBatchResults.push(batchResult);\n                    affected = collections_1.documentKeySet();\n                    return persistence_promise_1.PersistencePromise.resolve();\n                }\n                else {\n                    var documentBuffer_1 = new remote_document_change_buffer_1.RemoteDocumentChangeBuffer(_this.remoteDocuments);\n                    return _this.releaseBatchResults(txn, [batchResult], documentBuffer_1).next(function (promisedAffectedKeys) {\n                        affected = promisedAffectedKeys;\n                        return documentBuffer_1.apply(txn);\n                    });\n                }\n            })\n                .next(function () {\n                return _this.mutationQueue.performConsistencyCheck(txn);\n            })\n                .next(function () {\n                return _this.localDocuments.getDocuments(txn, affected);\n            });\n        });\n    };\n    /**\n     * Remove mutations from the MutationQueue for the specified batch;\n     * LocalDocuments will be recalculated.\n     *\n     * @returns The resulting modified documents.\n     */\n    LocalStore.prototype.rejectBatch = function (batchId) {\n        var _this = this;\n        return this.persistence.runTransaction('Reject batch', function (txn) {\n            var toReject;\n            var affectedKeys;\n            return _this.mutationQueue\n                .lookupMutationBatch(txn, batchId)\n                .next(function (promisedToReject) {\n                assert_1.assert(promisedToReject != null, 'Attempt to reject nonexistent batch!');\n                toReject = promisedToReject;\n                return _this.mutationQueue\n                    .getHighestAcknowledgedBatchId(txn)\n                    .next(function (lastAcked) {\n                    assert_1.assert(batchId > lastAcked, \"Acknowledged batches can't be rejected.\");\n                    return toReject;\n                });\n            })\n                .next(function () {\n                return _this.removeMutationBatch(txn, toReject);\n            })\n                .next(function (promisedAffectedKeys) {\n                affectedKeys = promisedAffectedKeys;\n                return _this.mutationQueue.performConsistencyCheck(txn);\n            })\n                .next(function () {\n                return _this.localDocuments.getDocuments(txn, affectedKeys);\n            });\n        });\n    };\n    /** Returns the last recorded stream token for the current user. */\n    LocalStore.prototype.getLastStreamToken = function () {\n        var _this = this;\n        return this.persistence.runTransaction('Get last stream token', function (txn) {\n            return _this.mutationQueue.getLastStreamToken(txn);\n        });\n    };\n    /**\n     * Sets the stream token for the current user without acknowledging any\n     * mutation batch. This is usually only useful after a stream handshake or in\n     * response to an error that requires clearing the stream token.\n     */\n    LocalStore.prototype.setLastStreamToken = function (streamToken) {\n        var _this = this;\n        return this.persistence.runTransaction('Set last stream token', function (txn) {\n            return _this.mutationQueue.setLastStreamToken(txn, streamToken);\n        });\n    };\n    /**\n     * Returns the last consistent snapshot processed (used by the RemoteStore to\n     * determine whether to buffer incoming snapshots from the backend).\n     */\n    LocalStore.prototype.getLastRemoteSnapshotVersion = function () {\n        return this.queryCache.getLastRemoteSnapshotVersion();\n    };\n    /**\n     * Update the \"ground-state\" (remote) documents. We assume that the remote\n     * event reflects any write batches that have been acknowledged or rejected\n     * (i.e. we do not re-apply local mutations to updates from this event).\n     *\n     * LocalDocuments are re-calculated if there are remaining mutations in the\n     * queue.\n     */\n    LocalStore.prototype.applyRemoteEvent = function (remoteEvent) {\n        var _this = this;\n        var documentBuffer = new remote_document_change_buffer_1.RemoteDocumentChangeBuffer(this.remoteDocuments);\n        return this.persistence.runTransaction('Apply remote event', function (txn) {\n            var promises = [];\n            objUtils.forEachNumber(remoteEvent.targetChanges, function (targetId, change) {\n                // Do not ref/unref unassigned targetIds - it may lead to leaks.\n                var queryData = _this.targetIds[targetId];\n                if (!queryData)\n                    return;\n                var mapping = change.mapping;\n                if (mapping) {\n                    // First make sure that all references are deleted\n                    if (mapping instanceof remote_event_1.ResetMapping) {\n                        promises.push(_this.queryCache\n                            .removeMatchingKeysForTargetId(txn, targetId)\n                            .next(function () {\n                            return _this.queryCache.addMatchingKeys(txn, mapping.documents, targetId);\n                        }));\n                    }\n                    else if (mapping instanceof remote_event_1.UpdateMapping) {\n                        promises.push(_this.queryCache\n                            .removeMatchingKeys(txn, mapping.removedDocuments, targetId)\n                            .next(function () {\n                            return _this.queryCache.addMatchingKeys(txn, mapping.addedDocuments, targetId);\n                        }));\n                    }\n                    else {\n                        return assert_1.fail('Unknown mapping type: ' + JSON.stringify(mapping));\n                    }\n                }\n                // Update the resume token if the change includes one. Don't clear\n                // any preexisting value.\n                var resumeToken = change.resumeToken;\n                if (resumeToken.length > 0) {\n                    queryData = queryData.update({\n                        resumeToken: resumeToken,\n                        snapshotVersion: change.snapshotVersion\n                    });\n                    _this.targetIds[targetId] = queryData;\n                    promises.push(_this.queryCache.addQueryData(txn, queryData));\n                }\n            });\n            var changedDocKeys = collections_1.documentKeySet();\n            remoteEvent.documentUpdates.forEach(function (key, doc) {\n                changedDocKeys = changedDocKeys.add(key);\n                promises.push(documentBuffer.getEntry(txn, key).next(function (existingDoc) {\n                    // Make sure we don't apply an old document version to the remote\n                    // cache, though we make an exception for SnapshotVersion.MIN which\n                    // can happen for manufactured events (e.g. in the case of a limbo\n                    // document resolution failing).\n                    if (existingDoc == null ||\n                        doc.version.equals(snapshot_version_1.SnapshotVersion.MIN) ||\n                        doc.version.compareTo(existingDoc.version) >= 0) {\n                        documentBuffer.addEntry(doc);\n                    }\n                    else {\n                        log.debug(LOG_TAG, 'Ignoring outdated watch update for ', key, '. Current version:', existingDoc.version, ' Watch version:', doc.version);\n                    }\n                    // The document might be garbage because it was unreferenced by\n                    // everything. Make sure to mark it as garbage if it is...\n                    _this.garbageCollector.addPotentialGarbageKey(key);\n                }));\n            });\n            // HACK: The only reason we allow a null snapshot version is so that we\n            // can synthesize remote events when we get permission denied errors while\n            // trying to resolve the state of a locally cached document that is in\n            // limbo.\n            var lastRemoteVersion = _this.queryCache.getLastRemoteSnapshotVersion();\n            var remoteVersion = remoteEvent.snapshotVersion;\n            if (!remoteVersion.equals(snapshot_version_1.SnapshotVersion.MIN)) {\n                assert_1.assert(remoteVersion.compareTo(lastRemoteVersion) >= 0, 'Watch stream reverted to previous snapshot?? ' +\n                    remoteVersion +\n                    ' < ' +\n                    lastRemoteVersion);\n                promises.push(_this.queryCache.setLastRemoteSnapshotVersion(txn, remoteVersion));\n            }\n            var releasedWriteKeys;\n            return persistence_promise_1.PersistencePromise.waitFor(promises)\n                .next(function () { return _this.releaseHeldBatchResults(txn, documentBuffer); })\n                .next(function (promisedReleasedWriteKeys) {\n                releasedWriteKeys = promisedReleasedWriteKeys;\n                return documentBuffer.apply(txn);\n            })\n                .next(function () {\n                return _this.localDocuments.getDocuments(txn, changedDocKeys.unionWith(releasedWriteKeys));\n            });\n        });\n    };\n    /**\n     * Notify local store of the changed views to locally pin documents.\n     */\n    LocalStore.prototype.notifyLocalViewChanges = function (viewChanges) {\n        var _this = this;\n        return this.persistence.runTransaction('Notify local view changes', function (txn) {\n            var promises = [];\n            var _loop_1 = function (view) {\n                promises.push(_this.queryCache\n                    .getQueryData(txn, view.query)\n                    .next(function (queryData) {\n                    assert_1.assert(queryData !== null, 'Local view changes contain unallocated query.');\n                    var targetId = queryData.targetId;\n                    _this.localViewReferences.addReferences(view.addedKeys, targetId);\n                    _this.localViewReferences.removeReferences(view.removedKeys, targetId);\n                }));\n            };\n            for (var _i = 0, viewChanges_1 = viewChanges; _i < viewChanges_1.length; _i++) {\n                var view = viewChanges_1[_i];\n                _loop_1(view);\n            }\n            return persistence_promise_1.PersistencePromise.waitFor(promises);\n        });\n    };\n    /**\n     * Gets the mutation batch after the passed in batchId in the mutation queue\n     * or null if empty.\n     * @param afterBatchId If provided, the batch to search after.\n     * @returns The next mutation or null if there wasn't one.\n     */\n    LocalStore.prototype.nextMutationBatch = function (afterBatchId) {\n        var _this = this;\n        return this.persistence.runTransaction('Get next mutation batch', function (txn) {\n            if (afterBatchId === undefined) {\n                afterBatchId = mutation_batch_1.BATCHID_UNKNOWN;\n            }\n            return _this.mutationQueue.getNextMutationBatchAfterBatchId(txn, afterBatchId);\n        });\n    };\n    /**\n     * Read the current value of a Document with a given key or null if not\n     * found - used for testing.\n     */\n    LocalStore.prototype.readDocument = function (key) {\n        var _this = this;\n        return this.persistence.runTransaction('read document', function (txn) {\n            return _this.localDocuments.getDocument(txn, key);\n        });\n    };\n    /**\n     * Assigns the given query an internal ID so that its results can be pinned so\n     * they don't get GC'd. A query must be allocated in the local store before\n     * the store can be used to manage its view.\n     */\n    LocalStore.prototype.allocateQuery = function (query) {\n        var _this = this;\n        return this.persistence.runTransaction('Allocate query', function (txn) {\n            var queryData;\n            return _this.queryCache\n                .getQueryData(txn, query)\n                .next(function (cached) {\n                if (cached) {\n                    // This query has been listened to previously, so reuse the\n                    // previous targetID.\n                    // TODO(mcg): freshen last accessed date?\n                    queryData = cached;\n                    return persistence_promise_1.PersistencePromise.resolve();\n                }\n                else {\n                    var targetId = _this.targetIdGenerator.next();\n                    queryData = new query_data_1.QueryData(query, targetId, query_data_1.QueryPurpose.Listen);\n                    return _this.queryCache.addQueryData(txn, queryData);\n                }\n            })\n                .next(function () {\n                assert_1.assert(!_this.targetIds[queryData.targetId], 'Tried to allocate an already allocated query: ' + query);\n                _this.targetIds[queryData.targetId] = queryData;\n                return queryData;\n            });\n        });\n    };\n    /** Unpin all the documents associated with the given query. */\n    LocalStore.prototype.releaseQuery = function (query) {\n        var _this = this;\n        return this.persistence.runTransaction('Release query', function (txn) {\n            return _this.queryCache\n                .getQueryData(txn, query)\n                .next(function (queryData) {\n                assert_1.assert(queryData != null, 'Tried to release nonexistent query: ' + query);\n                _this.localViewReferences.removeReferencesForId(queryData.targetId);\n                delete _this.targetIds[queryData.targetId];\n                if (_this.garbageCollector.isEager) {\n                    return _this.queryCache.removeQueryData(txn, queryData);\n                }\n                else {\n                    return persistence_promise_1.PersistencePromise.resolve();\n                }\n            })\n                .next(function () {\n                // If this was the last watch target, then we won't get any more\n                // watch snapshots, so we should release any held batch results.\n                if (objUtils.isEmpty(_this.targetIds)) {\n                    var documentBuffer_2 = new remote_document_change_buffer_1.RemoteDocumentChangeBuffer(_this.remoteDocuments);\n                    return _this.releaseHeldBatchResults(txn, documentBuffer_2).next(function () {\n                        documentBuffer_2.apply(txn);\n                    });\n                }\n                else {\n                    return persistence_promise_1.PersistencePromise.resolve();\n                }\n            });\n        });\n    };\n    /**\n     * Runs the specified query against all the documents in the local store and\n     * returns the results.\n     */\n    LocalStore.prototype.executeQuery = function (query) {\n        var _this = this;\n        return this.persistence.runTransaction('Execute query', function (txn) {\n            return _this.localDocuments.getDocumentsMatchingQuery(txn, query);\n        });\n    };\n    /**\n     * Returns the keys of the documents that are associated with the given\n     * target id in the remote table.\n     */\n    LocalStore.prototype.remoteDocumentKeys = function (targetId) {\n        var _this = this;\n        return this.persistence.runTransaction('Remote document keys', function (txn) {\n            return _this.queryCache.getMatchingKeysForTargetId(txn, targetId);\n        });\n    };\n    /**\n     * Collect garbage if necessary.\n     * Should be called periodically by Sync Engine to recover resources. The\n     * implementation must guarantee that GC won't happen in other places than\n     * this method call.\n     */\n    LocalStore.prototype.collectGarbage = function () {\n        var _this = this;\n        // Call collectGarbage regardless of whether isGCEnabled so the referenceSet\n        // doesn't continue to accumulate the garbage keys.\n        return this.persistence.runTransaction('Garbage collection', function (txn) {\n            return _this.garbageCollector.collectGarbage(txn).next(function (garbage) {\n                var promises = [];\n                garbage.forEach(function (key) {\n                    promises.push(_this.remoteDocuments.removeEntry(txn, key));\n                });\n                return persistence_promise_1.PersistencePromise.waitFor(promises);\n            });\n        });\n    };\n    LocalStore.prototype.releaseHeldBatchResults = function (txn, documentBuffer) {\n        var toRelease = [];\n        for (var _i = 0, _a = this.heldBatchResults; _i < _a.length; _i++) {\n            var batchResult = _a[_i];\n            if (!this.isRemoteUpToVersion(batchResult.commitVersion)) {\n                break;\n            }\n            toRelease.push(batchResult);\n        }\n        if (toRelease.length === 0) {\n            return persistence_promise_1.PersistencePromise.resolve(collections_1.documentKeySet());\n        }\n        else {\n            this.heldBatchResults.splice(0, toRelease.length);\n            return this.releaseBatchResults(txn, toRelease, documentBuffer);\n        }\n    };\n    LocalStore.prototype.isRemoteUpToVersion = function (version) {\n        // If there are no watch targets, then we won't get remote snapshots, and\n        // we are always \"up-to-date.\"\n        var lastRemoteVersion = this.queryCache.getLastRemoteSnapshotVersion();\n        return (version.compareTo(lastRemoteVersion) <= 0 ||\n            objUtils.isEmpty(this.targetIds));\n    };\n    LocalStore.prototype.shouldHoldBatchResult = function (version) {\n        // Check if watcher isn't up to date or prior results are already held.\n        return (!this.isRemoteUpToVersion(version) || this.heldBatchResults.length > 0);\n    };\n    LocalStore.prototype.releaseBatchResults = function (txn, batchResults, documentBuffer) {\n        var _this = this;\n        var promiseChain = persistence_promise_1.PersistencePromise.resolve();\n        var _loop_2 = function (batchResult) {\n            promiseChain = promiseChain.next(function () {\n                return _this.applyWriteToRemoteDocuments(txn, batchResult, documentBuffer);\n            });\n        };\n        for (var _i = 0, batchResults_1 = batchResults; _i < batchResults_1.length; _i++) {\n            var batchResult = batchResults_1[_i];\n            _loop_2(batchResult);\n        }\n        return promiseChain.next(function () {\n            return _this.removeMutationBatches(txn, batchResults.map(function (result) { return result.batch; }));\n        });\n    };\n    LocalStore.prototype.removeMutationBatch = function (txn, batch) {\n        return this.removeMutationBatches(txn, [batch]);\n    };\n    /** Removes all the mutation batches named in the given array. */\n    LocalStore.prototype.removeMutationBatches = function (txn, batches) {\n        var affectedDocs = collections_1.documentKeySet();\n        for (var _i = 0, batches_2 = batches; _i < batches_2.length; _i++) {\n            var batch = batches_2[_i];\n            for (var _a = 0, _b = batch.mutations; _a < _b.length; _a++) {\n                var mutation = _b[_a];\n                var key = mutation.key;\n                affectedDocs = affectedDocs.add(key);\n            }\n        }\n        return this.mutationQueue\n            .removeMutationBatches(txn, batches)\n            .next(function () { return affectedDocs; });\n    };\n    LocalStore.prototype.applyWriteToRemoteDocuments = function (txn, batchResult, documentBuffer) {\n        var batch = batchResult.batch;\n        var docKeys = batch.keys();\n        var promiseChain = persistence_promise_1.PersistencePromise.resolve();\n        docKeys.forEach(function (docKey) {\n            promiseChain = promiseChain\n                .next(function () {\n                return documentBuffer.getEntry(txn, docKey);\n            })\n                .next(function (remoteDoc) {\n                var doc = remoteDoc;\n                var ackVersion = batchResult.docVersions.get(docKey);\n                assert_1.assert(ackVersion !== null, 'ackVersions should contain every doc in the write.');\n                if (!doc || doc.version.compareTo(ackVersion) < 0) {\n                    doc = batch.applyToRemoteDocument(docKey, doc, batchResult);\n                    if (!doc) {\n                        assert_1.assert(!remoteDoc, 'Mutation batch ' +\n                            batch +\n                            ' applied to document ' +\n                            remoteDoc +\n                            ' resulted in null');\n                    }\n                    else {\n                        documentBuffer.addEntry(doc);\n                    }\n                }\n            });\n        });\n        return promiseChain;\n    };\n    return LocalStore;\n}());\nexports.LocalStore = LocalStore;\n\n//# sourceMappingURL=local_store.js.map\n"},"hash":"cf50924e3ea4867ab87a95de7cfee802"}